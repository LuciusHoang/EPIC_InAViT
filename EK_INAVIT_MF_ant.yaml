# EK_INAVIT_MF_ant.yaml — Updated for HOI boxes at test-time (CPU/MPS friendly)

# ------------------------------
# InAViT / HOI transformer bits
# ------------------------------
HOIVIT:
  ENABLE: True          # make sure HOI path is active
  O: 4                  # max objects per frame (matches our bbox builder)
  U: 1
  LAYERS: [1, 6, 10]
  USE_MOTION_STREAM: True
  MOTION_STREAM_ATTN_TYPE: joint
  DOUBLEATTENTION: False
  # Hints some forks support (ignored if unknown):
  # USE_BOXES: True
  # BOX_COORDS_NORMALIZED: True   # we pass 0–1 coords; set False if your model expects 224-pixel coords

EPICKITCHENS:
  ANTICIPATION: True     # action-anticipation setting (action head)
  SAVESCORES: False

# ------------------------------
# Train/Test toggles
# ------------------------------
TRAIN:
  ENABLE: False
  DATASET: epickitchens
  BATCH_SIZE: 4
  EVAL_PERIOD: 3
  CHECKPOINT_PERIOD: 1
  AUTO_RESUME: True
  MIXED_PRECISION: False
  CHECKPOINT_EPOCH_RESET: True
  # Use your local relative path (not /checkpoints/… which is absolute):
  CHECKPOINT_FILE_PATH: checkpoints/checkpoint_epoch_00081.pyth

TEST:
  ENABLE: True
  DATASET: epickitchens
  BATCH_SIZE: 1
  NUM_ENSEMBLE_VIEWS: 1
  NUM_SPATIAL_CROPS: 1
  # Some repos have explicit test-time HOI flags. If your fork supports them, keep True:
  # USE_HOIVIT: True
  # USE_BOXES: True

# ------------------------------
# Data / sampling
# ------------------------------
DATA:
  NUM_FRAMES: 16
  SAMPLING_RATE: 4
  TRAIN_JITTER_SCALES: [256, 320]
  TRAIN_CROP_SIZE: 224
  TEST_CROP_SIZE: 224
  INPUT_CHANNEL_NUM: [3]
  MEAN: [0.5, 0.5, 0.5]
  STD: [0.5, 0.5, 0.5]
  PATH_TO_DATA_DIR: /Volumes/T7_Shield/inference  # not used by our main.py, but fine to keep

AUG:
  NUM_SAMPLE: 1
  ENABLE: True
  DIFFERENT_AUG_PER_FRAME: True
  COLOR_JITTER: 0.0
  AA_TYPE: rand-m7-n4-mstd0.5-inc1
  INTERPOLATION: bicubic
  RE_PROB: 0.0
  RE_MODE: pixel
  RE_COUNT: 1
  RE_SPLIT: False

# ------------------------------
# Optimization (kept for completeness)
# ------------------------------
SOLVER:
  HOIVIT_BASE_LR: 1e-4
  BASE_LR: 1e-5
  LR_POLICY: steps_with_relative_lrs
  LRS: [1, 0.1, 0.01]
  STEPS: [0, 29, 60]
  MAX_EPOCH: 100
  MOMENTUM: 0.9
  WEIGHT_DECAY: 5e-2
  WARMUP_EPOCHS: 0.0
  OPTIMIZING_METHOD: adamw

# ------------------------------
# Backbone / head
# ------------------------------
SLOWFAST:
  ALPHA: 8

MF:
  PATCH_SIZE: 16
  PATCH_SIZE_TEMP: 2
  CHANNELS: 3
  EMBED_DIM: 768
  DEPTH: 12
  NUM_HEADS: 12
  MLP_RATIO: 4
  QKV_BIAS: True
  VIDEO_INPUT: True
  TEMPORAL_RESOLUTION: 8
  USE_MLP: True
  DROP: 0.0
  POS_DROPOUT: 0.0
  DROP_PATH: 0.2
  IM_PRETRAINED: True
  HEAD_DROPOUT: 0.0
  HEAD_ACT: tanh
  PRETRAINED_WEIGHTS: vit_1k
  ATTN_LAYER: trajectory

MODEL:
  NUM_CLASSES: 3806          # keep consistent with your checkpoint
  ARCH: slow
  MODEL_NAME: Motionformer
  LOSS_FUNC: label_smoothing_cross_entropy

# ------------------------------
# Loader / runtime
# ------------------------------
DATA_LOADER:
  NUM_WORKERS: 0
  PIN_MEMORY: False

NUM_GPUS: 0
NUM_SHARDS: 1
RNG_SEED: 0
OUTPUT_DIR: checkpoints/hoivit_ek_wmotion_ant

TENSORBOARD:
  ENABLE: True